{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: problog in /Users/william/opt/anaconda3/lib/python3.8/site-packages (2.2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install problog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import string\n",
    "import random\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the dataset\n",
    "#### We will read the dataset and split tthe dataset into traininng set and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the dataset\n",
    "#### We will read the dataset from the 'sms_spam' cvs database and name the two columns as Label and Message. Label column shows if the message is spam or ham. Message column shows the original SMS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms = pd.read_csv('sms_spam', sep='\\t', names=['Label', 'Message'])\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 5572 messages in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting the dataset into training set and test set\n",
    "#### We will carefully split the 80% dataset into training and 20% dataset into test to ensure unbiased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                            Message\n",
      "0   ham                       Yep, by the pretty sculpture\n",
      "1   ham      Yes, princess. Are you going to make me moan?\n",
      "2   ham                         Welp apparently he retired\n",
      "3   ham                                            Havent.\n",
      "4   ham  I forgot 2 ask ü all smth.. There's a card on ...\n",
      "  Label                                            Message\n",
      "0   ham  Yeah do! Don‘t stand to close tho- you‘ll catc...\n",
      "1   ham  Hi , where are you? We're at  and they're not ...\n",
      "2   ham        If you r @ home then come down within 5 min\n",
      "3   ham  When're you guys getting back? G said you were...\n",
      "4   ham  Tell my  bad character which u Dnt lik in me. ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomize the dataset\n",
    "sms_randomized = sms.sample(frac=1, random_state=1)\n",
    "\n",
    "# 20% test set and 80% training set\n",
    "test_index = math.floor(5572 * 0.2)\n",
    "\n",
    "test_sms = sms_randomized[:test_index]\n",
    "training_sms = sms_randomized[test_index:]\n",
    "\n",
    "test_sms = test_sms.reset_index(drop = True)\n",
    "training_sms = training_sms.reset_index(drop = True)\n",
    "\n",
    "print(test_sms.head())\n",
    "print(training_sms.head())\n",
    "type(training_sms['Message'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "#### We will do the data cleaning by removing all the punctuation and transform words to lower case in all the messages and splitting the message into words for training dataset. At the end, we will generate a table which shows all the message in the traning set, and the number of times that each unique word appears in each message.¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Remove all the punctuation and transform words to lower case in the messages\n",
    "#### In order to find the scam words, we need to unify the way each word exists and remove the information we don't need like punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                            Message\n",
      "0   ham                        yep by the pretty sculpture\n",
      "1   ham         yes princess are you going to make me moan\n",
      "2   ham                         welp apparently he retired\n",
      "3   ham                                             havent\n",
      "4   ham  i forgot 2 ask ü all smth theres a card on da ...\n",
      "  Label                                            Message\n",
      "0   ham  yeah do don‘t stand to close tho you‘ll catch ...\n",
      "1   ham  hi  where are you were at  and theyre not keen...\n",
      "2   ham         if you r  home then come down within 5 min\n",
      "3   ham  whenre you guys getting back g said you were t...\n",
      "4   ham  tell my  bad character which u dnt lik in me i...\n"
     ]
    }
   ],
   "source": [
    "punctuation = string.punctuation\n",
    "\n",
    "# Remove all the punctuation in the messages of testing data\n",
    "for i in range(len(test_sms)):\n",
    "    for l in test_sms[\"Message\"][i]:\n",
    "        if l in punctuation:\n",
    "            test_sms[\"Message\"][i] = test_sms[\"Message\"][i].replace(l, \"\")\n",
    "    # Transform to lower case\n",
    "    test_sms[\"Message\"][i] = test_sms[\"Message\"][i].lower()\n",
    "\n",
    "# Remove all the punctuation in the messages of training data\n",
    "for i in range(len(training_sms)):\n",
    "    for l in training_sms[\"Message\"][i]:\n",
    "        if l in punctuation:\n",
    "            training_sms[\"Message\"][i] = training_sms[\"Message\"][i].replace(l, \"\")\n",
    "            \n",
    "    # Transform to lower case\n",
    "    training_sms[\"Message\"][i] = training_sms[\"Message\"][i].lower()\n",
    "            \n",
    "print(test_sms.head())\n",
    "print(training_sms.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting the message into words for training dataset\n",
    "#### In order to calculate the probability of each word given Spam and the probability of each word given Ham, we need to split the message into words and remove some of the term that is not determined as a English word, and then count how many times each unique word exists in each message. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Finding all the words in the dataset\n",
    "#### We will split each message into words. If the word is empty word, a single character, or a number, it would not be determined as a word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for message in training_sms['Message']:\n",
    "    words_sms = message.split()\n",
    "    for word in words_sms:\n",
    "        #empty word, numbers and single character will not be counted as valid words\n",
    "        if word not in words and word != \"\" and any(char.isdigit() for char in word) == False and len(word) > 1:\n",
    "            words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7322"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words) # There are 8484 unique words in all training messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Counting the number times of each words appear in each message\n",
    "#### We will generate a table where each column represents a word and each row represents each message. This table will show us in each message, what is the number of times each word appears. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = {}\n",
    "for word in words:\n",
    "    \n",
    "    words_count[word] = [] \n",
    "\n",
    "for message in training_sms['Message']:\n",
    "    for word in words:\n",
    "        count = message.count(word)\n",
    "        words_count[word].append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeah</th>\n",
       "      <th>do</th>\n",
       "      <th>don‘t</th>\n",
       "      <th>stand</th>\n",
       "      <th>to</th>\n",
       "      <th>close</th>\n",
       "      <th>tho</th>\n",
       "      <th>you‘ll</th>\n",
       "      <th>catch</th>\n",
       "      <th>something</th>\n",
       "      <th>...</th>\n",
       "      <th>skyving</th>\n",
       "      <th>kkyesterday</th>\n",
       "      <th>arr</th>\n",
       "      <th>oscar</th>\n",
       "      <th>assumed</th>\n",
       "      <th>ceri</th>\n",
       "      <th>rebel</th>\n",
       "      <th>dreamz</th>\n",
       "      <th>buddy</th>\n",
       "      <th>recdthirtyeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   yeah  do  don‘t  stand  to  close  tho  you‘ll  catch  something  ...  \\\n",
       "0     1   2      1      1   1      1    1       1      1          1  ...   \n",
       "1     0   2      0      0   2      0    0       0      0          0  ...   \n",
       "2     0   1      0      0   0      0    0       0      0          0  ...   \n",
       "3     0   0      0      0   0      0    0       0      0          0  ...   \n",
       "4     0   0      0      0   1      0    0       0      0          0  ...   \n",
       "\n",
       "   skyving  kkyesterday  arr  oscar  assumed  ceri  rebel  dreamz  buddy  \\\n",
       "0        0            0    0      0        0     0      0       0      0   \n",
       "1        0            0    0      0        0     0      0       0      0   \n",
       "2        0            0    0      0        0     0      0       0      0   \n",
       "3        0            0    0      0        0     0      0       0      0   \n",
       "4        0            0    0      0        0     0      0       0      0   \n",
       "\n",
       "   recdthirtyeight  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "\n",
       "[5 rows x 7322 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_data = pd.DataFrame(words_count)\n",
    "words_count_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Combine the words_count dataframe with the training_sms dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>yeah</th>\n",
       "      <th>do</th>\n",
       "      <th>don‘t</th>\n",
       "      <th>stand</th>\n",
       "      <th>to</th>\n",
       "      <th>close</th>\n",
       "      <th>tho</th>\n",
       "      <th>you‘ll</th>\n",
       "      <th>...</th>\n",
       "      <th>skyving</th>\n",
       "      <th>kkyesterday</th>\n",
       "      <th>arr</th>\n",
       "      <th>oscar</th>\n",
       "      <th>assumed</th>\n",
       "      <th>ceri</th>\n",
       "      <th>rebel</th>\n",
       "      <th>dreamz</th>\n",
       "      <th>buddy</th>\n",
       "      <th>recdthirtyeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yeah do don‘t stand to close tho you‘ll catch ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>hi  where are you were at  and theyre not keen...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you r  home then come down within 5 min</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>whenre you guys getting back g said you were t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>tell my  bad character which u dnt lik in me i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message  yeah  do  don‘t  \\\n",
       "0   ham  yeah do don‘t stand to close tho you‘ll catch ...     1   2      1   \n",
       "1   ham  hi  where are you were at  and theyre not keen...     0   2      0   \n",
       "2   ham         if you r  home then come down within 5 min     0   1      0   \n",
       "3   ham  whenre you guys getting back g said you were t...     0   0      0   \n",
       "4   ham  tell my  bad character which u dnt lik in me i...     0   0      0   \n",
       "\n",
       "   stand  to  close  tho  you‘ll  ...  skyving  kkyesterday  arr  oscar  \\\n",
       "0      1   1      1    1       1  ...        0            0    0      0   \n",
       "1      0   2      0    0       0  ...        0            0    0      0   \n",
       "2      0   0      0    0       0  ...        0            0    0      0   \n",
       "3      0   0      0    0       0  ...        0            0    0      0   \n",
       "4      0   1      0    0       0  ...        0            0    0      0   \n",
       "\n",
       "   assumed  ceri  rebel  dreamz  buddy  recdthirtyeight  \n",
       "0        0     0      0       0      0                0  \n",
       "1        0     0      0       0      0                0  \n",
       "2        0     0      0       0      0                0  \n",
       "3        0     0      0       0      0                0  \n",
       "4        0     0      0       0      0                0  \n",
       "\n",
       "[5 rows x 7324 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sms_count = pd.concat([training_sms, words_count_data], axis = 1)\n",
    "training_sms_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we have a table which has 4458 rows and 7324 columns. It means there are 4458 messges in training set and there are 7322 unique words in these messages in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 7324)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sms_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Spam Filter\n",
    "#### After computing the table, we can now build the spam filter. We will calculate the probability of Spam given a message Pr(Spam | Message) and the probability of Ham given a message Pr(Ham | Message). By comparing these two probability, we can classify if the message is Spam or Ham. \n",
    "#### To calculate Pr(Spam | Message), we will use Naive Bayes Algorithm: \n",
    "#### Pr(Spam | Message) = Pr(Spam) * (Pr(Word1 | Spam) * Pr(Word2 | Spam) ...)\n",
    "#### Pr(Ham | Message) = Pr(Ham) * (Pr(Word1 | Ham) * Pr(Word2 | Ham) ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculating the constants we need\n",
    "#### To calculate the probability of each word given Spam or Ham, we need to calculate some constants, such as the number of words in all the spam messages n_Spam, the number of words in all the ham message n_Ham, the number of words in all messages n_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_Spam: 11843\n",
      "n_Ham: 53084\n",
      "n_Words: 7322\n"
     ]
    }
   ],
   "source": [
    "#Splits the \"spam\" and \"ham\" messages\n",
    "training_spam = training_sms_count[training_sms_count[\"Label\"] == \"spam\"]\n",
    "training_ham = training_sms_count[training_sms_count[\"Label\"] == \"ham\"]\n",
    "\n",
    "#Calculate N_Spam: the number of words in all the spam messages\n",
    "n_Spam = 0\n",
    "for eachmessage in training_spam[\"Message\"]:\n",
    "    eachmessage = eachmessage.split(\" \")\n",
    "    curcount = 0\n",
    "    for eachword in eachmessage:\n",
    "        #empty word and numbers will not be counted as valid words\n",
    "        if eachword != \"\" and any(char.isdigit() for char in eachword) == False and len(word) > 1:\n",
    "            curcount += 1\n",
    "    n_Spam += curcount\n",
    "\n",
    "#Calculate N_Ham: the number of words in all the non-spam messages\n",
    "n_Ham = 0\n",
    "for eachmessage in training_ham[\"Message\"]:\n",
    "    eachmessage = eachmessage.split(\" \")\n",
    "    curcount = 0\n",
    "    for eachword in eachmessage:\n",
    "        #empty word and numbers will not be counted as valid words\n",
    "        if eachword != \"\" and any(char.isdigit() for char in eachword) == False and len(word) > 1:\n",
    "            curcount += 1\n",
    "    n_Ham += curcount\n",
    "\n",
    "#Calculate n_Words\n",
    "n_Words = len(words)\n",
    "    \n",
    "print(\"n_Spam:\", n_Spam)\n",
    "print(\"n_Ham:\", n_Ham)\n",
    "print(\"n_Words:\", n_Words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculating the probabilities of Pr(wi | Spam) and Pr(wi | Ham)\n",
    "#### Now we can calculate the probability of each given spam and given ham. \n",
    "#### Pr(wi | Spam) = n_(wi | Spam) / n_Spam\n",
    "#### Pr(wi | Ham) = n_(wi | Ham) / n_Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pSpamWord = {}\n",
    "pHamWord = {}\n",
    "\n",
    "for w in words:\n",
    "    # For Spam message\n",
    "    # Calculate N(wi|Spam)\n",
    "    count = 0\n",
    "    for i in training_spam[w]:\n",
    "        count += i\n",
    "    # Calculate the probability Pr(wi|spam)\n",
    "    prob = count / n_Spam\n",
    "    pSpamWord[w] = prob\n",
    "    \n",
    "    # For Ham message\n",
    "    # Calculate N(wi|Ham)\n",
    "    count = 0\n",
    "    for i in training_ham[w]:\n",
    "        count += i\n",
    "    # Calculate the probability Pr(wi|spam)\n",
    "    prob = count / n_Ham\n",
    "    pHamWord[w] = prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building the model\n",
    "#### Now we can build the spam filter. We will create a function called classify with one input parameter Message. The function can calculate the probability of Spam given Message and the probability Ham give Message. By comparing these two probability, the greater probability will determine whether the message is a Spam message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pSpam = len(training_spam) / len(training_sms_count) # Pr(Spam)\n",
    "pHam = len(training_ham) / len(training_sms_count) # Pr(Ham)\n",
    "\n",
    "def classify(message):\n",
    "    message = message.split(\" \")\n",
    "    # Calculating Pr(Spam|w1,w2...) and Pr(Ham|w1,w2...)\n",
    "    pSpamWords = 1\n",
    "    pHamWords = 1\n",
    "    for word in message:\n",
    "        if word in pSpamWord:\n",
    "            pSpamWords *= pSpamWord[word]\n",
    "            \n",
    "        if word in pHamWord:\n",
    "            pHamWords *= pHamWord[word]\n",
    "    \n",
    "    pSpamMessage = pSpam * pSpamWords\n",
    "    pHamMessage = pHam * pHamWords\n",
    "    \n",
    "    #print(pSpamMessage, pHamMessage)\n",
    "    if pSpamMessage > pHamMessage:\n",
    "        result = \"spam\"\n",
    "    elif pSpamMessage < pHamMessage:\n",
    "        result = \"ham\"\n",
    "    else:\n",
    "        result = \"Can't not classify\"\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following is an example of Spam message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('You have won a secret price! To claim, call 09050000301.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing\n",
    "#### After building the spam filter, we can use the testing set to get the prediction based on the spam filter. Here, we write a function called testing with one input parameter test that is the testing set. The function will output a new dataframe with the prediction for each testing message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep by the pretty sculpture</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes princess are you going to make me moan</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth theres a card on da ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message Prediction\n",
       "0   ham                        yep by the pretty sculpture        ham\n",
       "1   ham         yes princess are you going to make me moan        ham\n",
       "2   ham                         welp apparently he retired        ham\n",
       "3   ham                                             havent        ham\n",
       "4   ham  i forgot 2 ask ü all smth theres a card on da ...        ham"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def testing(test):\n",
    "    testing = []\n",
    "    test_result = test.copy()\n",
    "    for message in test['Message']:\n",
    "        prediction = classify(message)\n",
    "        testing.append(prediction)\n",
    "    test_result['Prediction'] = testing\n",
    "    return test_result\n",
    "    \n",
    "test_result = testing(test_sms)\n",
    "test_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking accuracy and Improving accuracy\n",
    "#### Here we will check the accuracy of our current algorithm. Furthermore, we will try using Laplace Smoothing to calculate Pr( Wi | Spam) and Pr( Wi | Ham) and check if it can improve the accuracy of our spam filter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check the accuracy of our current algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:1045\n",
      "Incorrect:69\n",
      "Accuracy:0.9380610412926391\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "n_test = len(test_result)\n",
    "    \n",
    "for i in range(n_test):\n",
    "    if test_result['Label'][i] == test_result['Prediction'][i]:\n",
    "        correct += 1\n",
    "\n",
    "incorrect = n_test - correct\n",
    "accuracy = correct/n_test\n",
    "\n",
    "print('Correct:' + str(correct))\n",
    "print('Incorrect:' + str(incorrect))\n",
    "print('Accuracy:' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that there are 1045 cases that their predictions match the actual result and 69 mistakes that their predicions do not match the actual result. Hence, the accuracy of our current algorithm is around 93.81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Increase Accuracy by using Laplace Smoothing\n",
    "#### Due to the limitation of our training dataset, it is impossible for us to explore all combinations of a group of words. So, we might encounter the zero probability problem when calculating Pr( Wi | Spam) and Pr( Wi | Ham). Therefore, we decide to use Lapace Smoothing to help us address this problem and our updated formulas are. \n",
    "#### Pr(wi | Spam) = (n_(wi | Spam) + alpha) / (n_Spam + alpha * n_Words)\n",
    "#### Pr(wi | Ham) = (n_(wi | Ham) + alpha) / (n_Ham + alpha * n_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "\n",
    "for w in words:\n",
    "    # For Spam message\n",
    "    # Calculate N(wi|Spam)\n",
    "    count = 0\n",
    "    for i in training_spam[w]:\n",
    "        count += i\n",
    "    # Calculate the probability Pr(wi|spam) by using Laplace Smoothing\n",
    "    prob = (count + alpha) / (n_Spam + alpha * n_Words)\n",
    "    pSpamWord[w] = prob\n",
    "    \n",
    "    # For Ham message\n",
    "    # Calculate N(wi|Ham)\n",
    "    count = 0\n",
    "    for i in training_ham[w]:\n",
    "        count += i\n",
    "    # Calculate the probability Pr(wi|spam) by using Lapace Smoothing\n",
    "    prob = (count + alpha) / (n_Ham + alpha * n_Words)\n",
    "    pHamWord[w] = prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construct a vocabulary table, which will include words commonly associated with spam. \n",
    "#### We can determine whether a word is fraud-related based on its probability of appearing in a spam message and then construct a vocabulary table with associated words of spam that have a high probability of Pr(Spam|wi). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          call      free      text       our       all       txt    mobile       top       mob       cal       ext\n",
      "----  --------  --------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "Spam  0.017584  0.010644  0.007253  0.016645  0.020141  0.009236  0.006627  0.007148  0.009392  0.017793  0.008192\n",
      "Ham   0.004354  0.000927  0.001208  0.00894   0.011141  0.000281  0.000166  0.000993  0.000166  0.004917  0.001937\n"
     ]
    }
   ],
   "source": [
    "# Finding some words commonly associated with spam\n",
    "spam_words = []\n",
    "for key in pSpamWord:\n",
    "    if pSpamWord[key] - pHamWord[key] > 0.006 and len(key) > 2:\n",
    "        spam_words.append(key)\n",
    "        \n",
    "# Making table of spam words\n",
    "table = {}\n",
    "for word in spam_words:\n",
    "    table[word] = [round(pSpamWord[word], 6), round(pHamWord[word], 6)]\n",
    "\n",
    "print(tabulate(table, headers='keys', showindex=('Spam', 'Ham')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing by getting the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep by the pretty sculpture</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes princess are you going to make me moan</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth theres a card on da ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message Prediction\n",
       "0   ham                        yep by the pretty sculpture        ham\n",
       "1   ham         yes princess are you going to make me moan        ham\n",
       "2   ham                         welp apparently he retired        ham\n",
       "3   ham                                             havent        ham\n",
       "4   ham  i forgot 2 ask ü all smth theres a card on da ...        ham"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result_smooth = testing(test_sms)\n",
    "test_result_smooth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Checking the accuracy of the algorithm with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:1101\n",
      "Incorrect:13\n",
      "Accuracy:0.9883303411131059\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "n_test = len(test_result_smooth)\n",
    "    \n",
    "for i in range(n_test):\n",
    "    if test_result_smooth['Label'][i] == test_result_smooth['Prediction'][i]:\n",
    "        correct += 1\n",
    "\n",
    "incorrect = n_test - correct\n",
    "accuracy = correct/n_test\n",
    "\n",
    "print('Correct:' + str(correct))\n",
    "print('Incorrect:' + str(incorrect))\n",
    "print('Accuracy:' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, with the new method, we improve our accuracy from 93.81% to 98.83% !!!\n",
    "#### It shows that Laplace Smoothing can really help the improvement of the accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Spam Filter using ProbLog (Probabilistic Programming Languages)\n",
    "#### In this part, we would like to use the power of probabilistic programming language to see if it can help us analyze our data more effectively. It would be a combination of Python and probabilistic programming languages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write a function getWordsProb\n",
    "\n",
    "#### We firstly need to write a function that can get the probability of each words in the message given Spam and given Ham. The function will input a message we want to check and output two lists which one of the list stores the probability of each words in the message given Spam and another stores the probability of each words in the message given Ham. We name these two lists as pSpamWord_list and pHamWord_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordsProb(message):\n",
    "    pSpamWord_list = {}\n",
    "    pHamWord_list = {}\n",
    "    message = message.split(\" \")\n",
    "    # Calculating Pr(Spam|w1,w2...) and Pr(Ham|w1,w2...)\n",
    "    for word in message:\n",
    "        if word in pSpamWord:\n",
    "            # pSpamWord: Pr(wi|spam)\n",
    "            #print(word)\n",
    "            #print(pSpamWord[word])\n",
    "            pSpamWord_list[word] = pSpamWord[word]\n",
    "\n",
    "        if word in pHamWord:\n",
    "            pHamWord_list[word] = pHamWord[word]\n",
    "    return pSpamWord_list, pHamWord_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate the ProbLog code\n",
    "#### As we learn from the related work, we know ProbLog is mostly written in Python, so this allows us to import ProbLog as a Python package. A ProbLog program can also be composed as a string. \n",
    "#### Here, we will generate a function called probLogClassifier which will generate our ProbLog code as a string and fed into the Python library called ProblogString. The function will finally output the prediction and the ProbLog code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problog.program import PrologString\n",
    "from problog import get_evaluatable\n",
    "\n",
    "def probLogClassifier(message):\n",
    "    modeltext = \"\"\"\n",
    "        % Probabilities\n",
    "        0.13::pSpam.\n",
    "        0.87::pHam.\n",
    "    \"\"\"\n",
    "\n",
    "    pSpamWord_list, pHamWord_list = getWordsProb(message)\n",
    "\n",
    "    spamClauses = \"\"\"\n",
    "        % Probability of words given Spam\n",
    "    \"\"\"\n",
    "    spamClauses += \"    \"\n",
    "    for word in pSpamWord_list:\n",
    "        #print(pSpamWord_list[word])\n",
    "        spamClauses += f'{pSpamWord_list[word]}::word_given_spam(\\'{word}\\') :- pSpam.'\n",
    "        spamClauses += '\\n'\n",
    "        spamClauses += '        '\n",
    "    modeltext += spamClauses\n",
    "\n",
    "    \n",
    "    hamClauses = \"\"\"\n",
    "        % Prbability of words given Ham\n",
    "    \"\"\"\n",
    "    hamClauses += '    '\n",
    "    for word in pHamWord_list:\n",
    "        hamClauses += f'{pHamWord_list[word]}::word_given_ham(\\'{word}\\') :- pHam.'\n",
    "        hamClauses += '\\n'\n",
    "        hamClauses += '        '\n",
    "    modeltext += hamClauses\n",
    "    \n",
    "    \n",
    "    messageClauses = \"\"\"\n",
    "        spam_given_message([]).\n",
    "        spam_given_message([H|L]) :-\n",
    "            word_given_spam(H),\n",
    "            spam_given_message(L).\n",
    "\n",
    "        ham_given_message([]).\n",
    "        ham_given_message([H|L]) :-\n",
    "            word_given_ham(H),\n",
    "            ham_given_message(L).\n",
    "\n",
    "        % Probability of Spam given a message\n",
    "        % Pr[Spam | w1, w2...] , Pr[Ham | w1, w2...]\n",
    "        probSpam(Message) :- spam_given_message(Message), pSpam.\n",
    "        probHam(Message) :- ham_given_message(Message), pHam.\n",
    "    \"\"\"\n",
    "\n",
    "    modeltext += messageClauses + '\\n'\n",
    "\n",
    "    queryText = '        '\n",
    "    queryText += f'query(probSpam(['\n",
    "    for word in pSpamWord_list:\n",
    "        if word != list(pSpamWord_list.keys())[-1]:\n",
    "            queryText += f'\\'{word}\\','\n",
    "        else:\n",
    "            queryText += f'\\'{word}\\''\n",
    "    queryText += '])).'\n",
    "    queryText += '\\n'\n",
    "\n",
    "    queryText += '        '\n",
    "    queryText += f'query(probHam(['\n",
    "    for word in pHamWord_list:\n",
    "        if word != list(pHamWord_list.keys())[-1]:\n",
    "            queryText += f'\\'{word}\\','\n",
    "        else:\n",
    "            queryText += f'\\'{word}\\''\n",
    "    queryText += '])).'\n",
    "\n",
    "    modeltext += queryText\n",
    "    #print(modeltext)\n",
    "    \n",
    "    # Create a Prolog program from the model text\n",
    "    program = PrologString(modeltext)\n",
    "    result = get_evaluatable().create_from(PrologString(modeltext)).evaluate()\n",
    "\n",
    "    probResult = []\n",
    "    for query, prob in result.items():\n",
    "        probResult.append(prob)\n",
    "        output = f\"Query: {query}\"\n",
    "        if \"Ham\" in output:\n",
    "            pHamMessage = prob\n",
    "        elif \"Spam\" in output:\n",
    "            pSpamMessage = prob\n",
    "    \n",
    "    if pSpamMessage > pHamMessage:\n",
    "        result = \"spam\"\n",
    "    elif pSpamMessage < pHamMessage:\n",
    "        result = \"ham\"\n",
    "    else:\n",
    "        result = \"Can't not classify\"\n",
    "            \n",
    "    return result, modeltext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following is the example of running the ProbLog classifier. It prints out the ProbLog code and the prediction of the message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        % Probabilities\n",
      "        0.13::pSpam.\n",
      "        0.87::pHam.\n",
      "    \n",
      "        % Probability of words given Spam\n",
      "        0.005687451082702843::word_given_spam('have') :- pSpam.\n",
      "        0.003443777719801722::word_given_spam('won') :- pSpam.\n",
      "        0.0006261414036003131::word_given_spam('secret') :- pSpam.\n",
      "        0.017584137751108793::word_given_spam('call') :- pSpam.\n",
      "        \n",
      "        % Prbability of words given Ham\n",
      "        0.006373539052412012::word_given_ham('have') :- pHam.\n",
      "        0.0013409263980399299::word_given_ham('won') :- pHam.\n",
      "        0.0001324371751150548::word_given_ham('secret') :- pHam.\n",
      "        0.004353872131907427::word_given_ham('call') :- pHam.\n",
      "        \n",
      "        spam_given_message([]).\n",
      "        spam_given_message([H|L]) :-\n",
      "            word_given_spam(H),\n",
      "            spam_given_message(L).\n",
      "\n",
      "        ham_given_message([]).\n",
      "        ham_given_message([H|L]) :-\n",
      "            word_given_ham(H),\n",
      "            ham_given_message(L).\n",
      "\n",
      "        % Probability of Spam given a message\n",
      "        % Pr[Spam | w1, w2...] , Pr[Ham | w1, w2...]\n",
      "        probSpam(Message) :- spam_given_message(Message), pSpam.\n",
      "        probHam(Message) :- ham_given_message(Message), pHam.\n",
      "    \n",
      "        query(probSpam(['have','won','secret','call'])).\n",
      "        query(probHam(['have','won','secret','call'])).\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "message = \"You have won a secret price! To claim, call 09050000301.\"\n",
    "prediction, modeltext = probLogClassifier(message)\n",
    "print(modeltext)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep by the pretty sculpture</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes princess are you going to make me moan</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth theres a card on da ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message Prediction\n",
       "0   ham                        yep by the pretty sculpture        ham\n",
       "1   ham         yes princess are you going to make me moan        ham\n",
       "2   ham                         welp apparently he retired        ham\n",
       "3   ham                                             havent        ham\n",
       "4   ham  i forgot 2 ask ü all smth theres a card on da ...        ham"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = []\n",
    "for message in test_sms['Message']:\n",
    "    prediction, modeltext = probLogClassifier(message)\n",
    "    testing.append(prediction)\n",
    "\n",
    "test_result_probLog = test_sms.copy()\n",
    "test_result_probLog['Prediction'] = testing\n",
    "test_result_probLog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accuracy of ProbLog Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:1101\n",
      "Incorrect:13\n",
      "Accuracy:0.9883303411131059\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "n_test = len(test_result_probLog)\n",
    "    \n",
    "for i in range(n_test):\n",
    "    if test_result_probLog['Label'][i] == test_result_probLog['Prediction'][i]:\n",
    "        correct += 1\n",
    "\n",
    "incorrect = n_test - correct\n",
    "accuracy = correct/n_test\n",
    "\n",
    "print('Correct:' + str(correct))\n",
    "print('Incorrect:' + str(incorrect))\n",
    "print('Accuracy:' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, by using the ProbLog classifer, the accuracy is 98.83% which shows the feasibility ProbLog classifier. It implements a combination of Python and ProbLog and it is meaningful that we have learned how to run ProbLog code in Python. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
